{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocab=Counter()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./train.txt', 'r')\n",
    "\n",
    "sentences = []\n",
    "sentence = []\n",
    "ner_set = set()\n",
    "  \n",
    "for line in f:\n",
    "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
    "        if len(sentence) > 0:\n",
    "            sentences.append(sentence)\n",
    "            sentence=[]\n",
    "        continue\n",
    "    splits = line.split(' ')\n",
    "    # 공백을 기준으로 속성을 구분한다.\n",
    "    splits[-1] = re.sub(r'\\n', '', splits[-1])\n",
    "    # 개체명 태깅 뒤에 붙어있는 줄바꿈 표시 \\n을 제거한다.\n",
    "    word=splits[0].lower()\n",
    "    # 단어들은 소문자로 바꿔서 저장한다. 단어의 수를 줄이기 위해서이다.\n",
    "    vocab[word]=vocab[word]+1\n",
    "    # 단어마다 빈도 수가 몇 인지 기록한다.\n",
    "    sentence.append([word, splits[-1]])\n",
    "    # 단어와 개체명 태깅만 기록한다.\n",
    "    ner_set.add(splits[-1])\n",
    "    # set에다가 개체명 태깅을 집어 넣는다. 중복은 허용되지 않으므로\n",
    "    # 나중에 개체명 태깅이 어떤 종류가 있는지 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ner_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sorted=sorted(vocab.items(), key=lambda x:x[1], reverse=True)\n",
    "# vocab을 빈도수 순으로 정렬한다.\n",
    "vocab_sorted\n",
    "# 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {w: i + 2 for i, (w, n) in enumerate(vocab_sorted) if n > 5}\n",
    "word_to_index['PAD'] = 0  # 패딩을 위해 인덱스 0 할당\n",
    "word_to_index['OOV'] = 1  # 모르는 단어을 위해 인덱스 1 할당\n",
    "word_to_index # 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_to_index={}\n",
    "ner_to_index['PAD'] = 0\n",
    "i=1\n",
    "for ner in ner_set:\n",
    "    ner_to_index[ner]=i\n",
    "    i=i+1\n",
    "print(ner_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_to_index['I-PER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = []\n",
    "\n",
    "for s in sentences:\n",
    "    temp_X = []\n",
    "    for w, label in s:\n",
    "        try:\n",
    "            temp_X.append(word_to_index.get(w,1))\n",
    "        except KeyError:\n",
    "            temp_X.append(word_to_index['OOV'])\n",
    "\n",
    "    data_X.append(temp_X)\n",
    "print(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word={}\n",
    "for key, value in word_to_index.items(): # 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
    "    index_to_word[value] = key\n",
    "\n",
    "\n",
    "temp = []\n",
    "for index in data_X[0] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
    "    temp.append(index_to_word[index]) # 다시 단어로 변환\n",
    "\n",
    "print(sentences[0])    \n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = []\n",
    "\n",
    "for s in sentences:\n",
    "    temp_y = []\n",
    "    for w, label in s:\n",
    "            temp_y.append(ner_to_index.get(label))\n",
    "\n",
    "    data_y.append(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_X[:4]) # X 데이터 4개만 출력\n",
    "print(data_y[:4]) # y 데이터 4개만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(s) for s in data_X], bins=50)\n",
    "plt.xlabel('length of Data')\n",
    "plt.ylabel('number of Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(len(l) for l in data_X)) # 전체 데이터에서 길이가 가장 긴 샘플의 길이 출력\n",
    "print(max(len(l) for l in data_y)) # 전체 데이터에서 길이가 가장 긴 샘플의 길이 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=70\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "pad_X = pad_sequences(data_X, padding='post', maxlen=max_len)\n",
    "# data_X의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\n",
    "pad_y = pad_sequences(data_y, padding='post', maxlen=max_len)\n",
    "# data_y의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자0으로 채움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(len(l) for l in pad_X)) # 모든 데이터에서 길이가 가장 짧은 샘플의 길이 출력\n",
    "print(min(len(l) for l in pad_y)) # 모든 데이터에서 길이가 가장 짧은 샘플의 길이 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(pad_X, pad_y, test_size=.2, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = len(word_to_index)\n",
    "n_labels = len(ner_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words, output_dim=16, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(n_labels, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train2 = np_utils.to_categorical(y_train)\n",
    "y_train2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train2, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2 = np_utils.to_categorical(y_test)\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "index_to_word={}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "index_to_ner={}\n",
    "for key, value in ner_to_index.items():\n",
    "    index_to_ner[value] = key\n",
    "\n",
    "\n",
    "i=10 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "true = np.argmax(y_test2[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
    "    if w != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t], index_to_ner[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
